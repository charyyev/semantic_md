# This file acts as the base configuration file for the project.
# See configs/template.yaml for an example how to create a deviating configuration file
# By default the config/user.yaml configuration file is used.

# model_type specifies the class of model we aim to train

# For category 1 and 2, it is typically "uefficientnet_b4", which specifies the
# architecture used in the encoder. Variations to the "super-architecture" (eg. for
# models in category 2) are done under data_flags

# For category 3 it is either "multi_loss" for 2 heads, or "triple_loss" for 3.
# Do not specify in data_flag/type when using these models

# Finally we have "sobel_loss", "contour_loss" and "semantic_baseline" used in ablation
# studies
model_type: "uefficientnet_b4"
# specifies the type of encoding-decoding architecture used in multi_ and triple_loss
# can be either "DeepLabV3" or "UNet"
super_model: "UNet"
# used for naming saved models
note: "DICE"
device: "cuda"

# wandb settings
wandb:
    wandb: false
    entity: "semantic_md"
    project: "losses"
    group: null

resume:
    resume_training: false
    path: ""
    epoch: 0

# subpaths specified relative to project_root_dir specified in user.yaml
subpaths:
    output: "../output"
    data_location: "test_data"
    train_data: "source/datasets/paths/train_imgPath.txt"
    val_data: "source/datasets/paths/val_imgPath.txt"
    vis_data: "test_data/submission_path.txt"
    load: ""
    pretrained_weights_path: "pretrained_weights"
    logs: "logs"
    saved_figures: "saved_figures"

#
data_flags:
    # type specifies the overall architecture (used in category *2*)
    # can be concat, contour, semantic_convolution, simplified_onehot
    # do not specify when using category 3 models
    type: null
    ####################################################################################
    # concat: set type=concat, return_types=false
    # contour: set type=concat, return_types:contour=true
    # semantic_convolution: set type=semantic_convolution, return_types=false
    # simplified_onehot: set type=simplified_onehot, return_types:simplified_onehot=true
    #     parameters:simplified_onehot_classes=N
    ####################################################################################
    # segmentation classes are specified as the top classes (sorted by prevalence in the
    # dataset (max. 40).
    parameters:
        # specifies top x classes to be encoded for the segmentation map
        seg_classes: 40
        # specifies how many classes are encoded in onehot
        simplified_onehot_classes: 40
        # parameters used for sobel prediction
        sobel_threshold: 20
        sobel_ksize: 5
    # specify return_type get
    return_types:
        contour: false # true when type == contour
        simplified_onehot: false # true when type == simplified_onehot
        sobel: false # true when running sobel model

hyperparameters:
    train:
        batch_size: 32
        learning_rate: 0.001
        epochs: 15
        weight_decay: 0
        save_every: 2
        # depth loss, can be either "L1" or "berhu"
        depth_loss_type: "L1"
        # lambda used for weighing the segmentation losses
        lambda_semantic: 0.07
        # type of semantic loss function, can be CE, Dice, FTL, Dice_CE, FTL_CE
        semantic_loss_type: "Dice"
        # parameters for different semantic losses
        weight_lambda: 0.5
        weight_alpha: 0.8
        weight_gamma: 1.5
        # lambda used for weighing the contour losses
        lambda_contours: 0.1
        # lambda used for weighing the sobel losses
        lambda_sobel: 1
    val:
        batch_size: 32
        val_every: 1

transformations:
    resize:
        width: 342
        height: 256 
    depth_range:
        min: 0
        max:  15

save_names:
    weights: "weights.pth"
    optimizer: "optimizer.pth"

pretrained_names:
    weights: "weights.pth"
    pretrained_metadata: "weights_object.pickle"

# please use this to specify which model you are visualizing (do not have to change
# the other parameters)
visualize:
    start: 0
    model_type: "uefficientnet_b4"
    model_path: "/path/to/weights.pth"
    model_name: "naive"

# specify elasticity of leading pretrained weights
load:
    strict: true
